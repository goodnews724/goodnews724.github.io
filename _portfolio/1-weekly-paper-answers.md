---
title: 위클리 페이퍼 훑어보기
subtitle: 2025-08-12
image: assets/img/portfolio/04-thumbnail.jpg
alt: Weekly Paper
caption:
  title: 위클리 페이퍼 훑어보기
  subtitle: Tech
  thumbnail: assets/img/portfolio/04-thumbnail.jpg
---
# 위클리 페이퍼 후루꾸 답안

## #1. 데이터 분석 시작하기

**클래스와 인스턴스에 대해 설명해주세요.**

- 클래스는 객체가 가져야 할 속성과 메서드를 정의하는 설계도임. 붕어빵 틀 같은 거임.
- 인스턴스는 클래스에서 정의된 내용을 바탕으로 생성된 실제 객체임. 붕어빵 틀로 찍어낸 실제 붕어빵임.

**정적 메소드는 무엇이고, 어떻게 호출하나요?**

- 정적 메소드는 클래스에 속하지만 인스턴스 생성 없이 호출할 수 있는 메소드임.
- `@staticmethod` 데코레이터를 사용해서 정의하고 `Math.add(3, 5)` 이런 식으로 호출함.

## #2. 실전 파이썬 준비하기

**절대 경로와 상대 경로는 무엇인가요?**

- 절대 경로는 루트 디렉토리부터 시작하는 완전한 경로임. "서울시 강남구 역삼동 123-45번지"처럼 집 주소를 전체 다 쓰는 거임.
- 상대 경로는 현재 위치를 기준으로 하는 경로임. "우리 집에서 두 블록 앞 편의점"처럼 현재 내 위치를 기준으로 설명하는 거임.

**Git에서 branch는 무엇이고, 왜 사용하나요?**

- Branch는 독립적인 개발 라인을 만드는 Git 기능임. 요리할 때 메인 요리는 그대로 두고 새로운 소스를 따로 만들어보는 것과 같음.
- 새로운 기능 개발이나 실험을 메인 코드에 영향 주지 않고 안전하게 할 수 있어서 사용함. 망하면 그 브랜치만 버리면 됨.

## #3. 데이터 분석 기초

**제1종 오류와 제2종 오류에 대해 설명해주세요.**

- 제1종 오류는 실제로는 차이가 없는데 차이가 있다고 잘못 결론내리는 오류임. 화재경보기가 고기 굽는 연기 때문에 울리는 것처럼, 진짜 화재가 아닌데 화재라고 알리는 거임.
- 제2종 오류는 실제로는 차이가 있는데 차이가 없다고 잘못 결론내리는 오류임. 진짜 불이 났는데 화재경보기가 고장나서 안 울리는 것처럼, 진짜 문제가 있는데 못 찾는 거임.

**p값 (p-value)는 무엇인가요?**

- p값은 귀무가설이 참일 때 관찰된 결과가 우연히 나올 확률임. 동전 던지기에서 앞면이 8번 연속 나왔을 때 "이게 정말 우연일까?"하고 의심하는 것과 같음.
- 보통 p < 0.05 (5% 미만)이면 "우연이 아니다"라고 판단함.

**데이터 전처리 방법들에 대해 설명해 주세요.**

- 결측값 처리: 설문조사에서 나이 칸이 비어있을 때 삭제하거나 평균 나이로 채우는 거임.
- 이상값 처리: 키 측정에서 갑자기 300cm가 나왔을 때 "이건 오타겠지?" 하고 제거하는 거임.
- 정규화: 키(cm)와 몸무게(kg)를 비교할 때 단위가 달라서 0~1 사이로 맞춰주는 거임.
- 중복 제거: 같은 사람이 실수로 두 번 설문한 걸 하나로 합치는 거임.

**t-test에 대해 설명해 주세요.**

- t-test는 표본 평균들 사이의 차이가 통계적으로 유의한지 검정하는 방법임. A반과 B반 시험 점수 평균이 다를 때, 이게 우연인지 진짜 차이인지 판단하는 거임.
- 일표본(우리반 평균이 전국 평균과 다른가), 독립표본(A반과 B반이 다른가), 대응표본(약 먹기 전후가 다른가) 세 종류가 있음.

**사분위수에 대해 설명해주세요.**

- 사분위수는 데이터를 크기 순으로 정렬했을 때 4등분하는 지점들임. 반 학생들을 키 순서로 세웠을 때 1/4 지점, 절반 지점, 3/4 지점을 말하는 거임.
- Q1(하위 25%), Q2(중앙값), Q3(상위 25%)로 구성됨.

**기술통계와 추론통계는 무엇이고, 어떤 차이가 있나요?**

- 기술통계는 가지고 있는 데이터의 특성을 요약해서 설명하는 통계임. 우리반 시험 점수 평균이 80점이라고 설명하는 거임.
- 추론통계는 표본 데이터로 전체 모집단의 특성을 추측하는 통계임. 우리반 점수로 전체 학교 평균을 추측하는 거임.

## #4. 관계형 데이터베이스

**GROUP BY 절과 HAVING 절의 차이점은 무엇인가요?**

- GROUP BY는 데이터를 특정 기준으로 그룹화하는 절임. 학생들을 학과별로 묶는 것과 같음.
- HAVING은 그룹화된 결과에 조건을 거는 절임. 학과별로 묶은 후에 "평균 점수가 80점 이상인 학과만 보여줘"라고 하는 거임.

**데이터베이스에서 NULL 값이란 무엇인가요? NULL 값을 처리하는 MySQL 함수는 무엇이 있나요?**

- NULL은 값이 없음 또는 알 수 없음을 나타내는 특별한 값임. 전화번호 없는 사람의 전화번호 칸처럼 아예 비어있는 상태임.
- MySQL 함수: IFNULL(값이 NULL이면 다른 값으로 바꿔줘), COALESCE(여러 개 중 NULL 아닌 첫 번째 값), ISNULL(NULL인지 확인) 등이 있음.

**데이터베이스 정규화란 무엇인가요? 또, 정규화의 장단점은 무엇인가요?**

- 정규화는 데이터 중복을 최소화하고 무결성을 보장하기 위해 테이블을 분해하는 과정임. 한 서랍에 모든 걸 넣지 말고 종류별로 서랍을 나누는 것과 같음.
- 장점: 중복 데이터 줄어서 저장공간 절약, 데이터 일관성 향상
- 단점: 여러 테이블 합쳐야 해서 복잡해짐, 조회 속도 느려질 수 있음

**논리적 모델링에서 사용되는 주요 구성 요소인 엔터티, 속성, 관계에 대해 설명해주세요.**

- 엔터티는 데이터베이스에서 관리하고자 하는 객체나 개념임. 학생, 강의실, 교수 같은 실제 존재하는 것들임.
- 속성은 엔터티의 특성이나 성질을 나타내는 요소임. 학생의 이름, 학번, 전화번호 같은 정보들임.
- 관계는 엔터티들 간의 연관성을 나타냄. 학생이 수업을 듣는다, 교수가 수업을 가르친다 같은 연결고리임.

## #5. 데이터 수집 및 프로덕트 데이터 분석

**AARRR 프레임워크와 리텐션 개념을 설명해 주세요. Funnel 분석과의 연관성을 설명해 주세요.**

- AARRR은 Acquisition(획득), Activation(활성화), Retention(유지), Revenue(수익), Referral(추천)의 고객 생애주기 프레임워크임. 카페에서 손님이 처음 와서(획득) → 커피 마시고(활성화) → 단골 되고(유지) → 돈 쓰고(수익) → 친구 데려오는(추천) 과정과 같음.
- 리텐션은 고객이 서비스를 지속적으로 이용하는 비율임. 한 달 후에도 앱을 쓰는 사람이 얼마나 되는지 보는 거임.
- Funnel 분석은 각 단계별 전환율을 측정해서 AARRR 각 단계에서 얼마나 많은 사람이 빠져나가는지 파악하는 데 사용됨.

**코호트와 세그먼트의 차이점은 무엇인가요?**

- 코호트는 특정 시점에 동일한 경험을 한 사용자 그룹임. 2024년 1월에 가입한 사람들처럼 같은 달에 가입한 사람들을 묶는 거임.
- 세그먼트는 특정 특성이나 행동을 기준으로 나눈 사용자 그룹임. 20대 남성, 서울 거주자, 매일 앱 쓰는 사람 이런 식으로 특징별로 나누는 거임.

**RFM 분석이란 무엇이며, 이를 통해 고객을 어떻게 세분화할 수 있는지 설명해 주세요.**

- RFM은 Recency(최근성), Frequency(빈도), Monetary(금액)로 고객을 분석하는 방법임.
- Recency: 마지막 주문이 언제였는지 (어제 주문한 사람 vs 1년 전 주문한 사람)
- Frequency: 얼마나 자주 주문하는지 (주 3회 주문 vs 월 1회 주문)
- Monetary: 얼마나 많은 돈을 쓰는지 (한 번에 10만원 vs 한 번에 1만원)
- 이 세 지표로 고객을 VIP(최근에 자주 많이 쓴 사람), 신규(최근에 처음 쓴 사람), 이탈위험(예전엔 썼는데 요즘 안 쓰는 사람) 등으로 나눌 수 있음.

**원하는 제품/서비스를 하나 선택하여 해당 상품/서비스에서 가장 중요한 획득 지표는 무엇인지 설명해 주세요.**

- 배달앱(배민, 쿠팡이츠)의 경우 주문 완료율이 가장 중요한 획득 지표임.
- 앱 설치만 하고 주문 안 하면 의미 없고, 실제로 음식을 주문해야 진짜 고객이 되기 때문임. 배가 고파서 앱 깔고 실제로 치킨을 주문해야 진짜 획득된 거임.

**고객 생애 가치(LTV)를 계산하는 방법과 이 지표가 중요한 이유를 설명해 주세요.**

- LTV = 평균 구매금액 × 구매빈도 × 고객 유지기간으로 계산함.
- 예시: 커피숍에서 한 번에 5천원씩, 주 2회, 1년간 다니는 고객의 LTV = 5,000 × 2 × 52 = 52만원임.
- 이 지표가 중요한 이유는 고객 획득에 얼마까지 쓸 수 있는지 알 수 있기 때문임. LTV가 52만원이면 광고비로 10만원 써도 이득임.

**A/B 테스트의 장점과 단점, 그리고 단점을 해결하기 위한 방안들을 설명해 주세요.**

- 장점: 두 버전을 동시에 테스트해서 어떤 게 더 좋은지 확실히 알 수 있음. 빨간 버튼 vs 파란 버튼 중 어떤 게 더 클릭 많이 되는지 정확히 측정 가능.
- 단점: 시간 오래 걸리고, 사용자 많이 필요하고, 외부 요인(휴일, 이벤트 등) 때문에 결과가 왜곡될 수 있음.
- 해결 방안: 멀티암드 밴딧(좋은 쪽에 더 많은 트래픽 보내기), 점진적 출시(5% → 20% → 50% 이런 식으로), 사전에 필요한 사용자 수 계산해서 준비하기.

**A/B 테스트 결과에서 한 버전이 통계적으로 유의미하게 더 나은 결과를 보여주지 않는다면, 이를 어떻게 해석하고 다음 단계는 무엇인가요?**

- 두 버전이 거의 비슷하다는 의미이거나 사용자가 부족해서 차이를 못 찾은 것일 수 있음. 동전 10번 던져서 앞뒤 같이 나왔다고 동전이 공정하다고 확신할 수 없는 것처럼.
- 다음 단계: 더 오래 테스트하거나, 더 큰 차이를 만드는 새로운 버전을 만들거나, 다른 지표로 분석해보기.

**이벤트 데이터 로그 설계(Event Taxonomy)의 주요 구성 요소는 무엇이며, 각 요소가 어떤 역할을 하는지 설명해 주세요.**

- Event Name: 무슨 행동을 했는지 이름 (button_click, page_view, purchase 같은 거)
- Properties: 그 행동의 상세 정보 (어떤 버튼을 눌렀는지, 몇 시에 눌렀는지, 어느 페이지에서 눌렀는지)
- User ID: 누가 했는지 식별하는 번호 (같은 사람이 여러 번 한 행동인지 구분하려고)
- Timestamp: 언제 했는지 정확한 시간 (사용자 행동 패턴 파악하려고)

## #6. 머신러닝 기초

**지도 학습과 비지도 학습의 차이는 무엇인가요?**

- 지도 학습은 정답이 있는 데이터로 학습하는 방법임. 선생님이 "이건 고양이, 이건 강아지"라고 알려주면서 가르치는 것과 같음.
- 비지도 학습은 정답 없이 데이터의 패턴을 찾는 방법임. 동물 사진만 주고 "알아서 비슷한 것끼리 묶어봐"라고 하는 것과 같음.

**손실 함수(loss function)란 무엇이며, 왜 중요한가요?**

- 손실 함수는 모델의 예측값과 실제값 사이의 차이를 측정하는 함수임. 양궁에서 과녁 중심에서 얼마나 벗어났는지 측정하는 것과 같음.
- 이 값을 최소화하는 방향으로 모델이 학습하기 때문에 중요함. 계속 연습해서 과녁 중심에 더 가깝게 쏘려고 노력하는 거임.

**모델 학습 시 발생할 수 있는 편향과 분산에 대해 설명하고, 두 개념의 관계에 대해 설명해 주세요.**

- 편향은 모델이 체계적으로 틀리는 정도임. 양궁에서 항상 왼쪽으로 빗나가는 것처럼 한쪽으로 치우치는 거임.
- 분산은 예측값이 얼마나 들쭉날쭉한지를 나타냄. 양궁에서 화살이 사방으로 흩어지는 것과 같음.
- 둘은 트레이드오프 관계임. 편향을 줄이려고 하면 분산이 커지고, 분산을 줄이려고 하면 편향이 커지는 경우가 많음.

**K-폴드 교차 검증에서 K의 값을 선택할 때 고려해야 할 점은 무엇인가요?**

- K가 클수록 더 정확한 성능 추정이 가능하지만 계산 시간이 오래 걸림. 시험을 10번 보면 1번 볼 때보다 실력을 정확히 알 수 있지만 시간이 10배 걸리는 것과 같음.
- K가 너무 작으면 성능 추정이 불안정하고, 너무 크면 계산 비용이 많이 듦. 보통 5-10 정도를 많이 씀.

**결정 트리의 장점과 단점은 무엇인가요?**

- 장점: 이해하기 쉽고 해석이 간단함. "키가 170cm 이상이고 몸무게가 70kg 이상이면 농구선수" 이런 식으로 규칙이 명확함.
- 단점: 과적합이 쉽게 일어나고 작은 데이터 변화에 민감함. 나무가 너무 복잡하게 자라면 새로운 데이터에는 잘 안 맞을 수 있음.

**부스팅은 어떤 특징을 가진 앙상블 기법인가요? AdaBoost 이외의 부스팅 모델들과 특징을 설명해 주세요.**- 부스팅은 약한 학습기들을 순차적으로 학습시켜서 이전 모델의 오류를 보완하는 앙상블 기법임. 학생이 시험을 보고 틀린 문제를 다시 공부해서 다음 시험에서 더 잘하는 것과 같음.

- AdaBoost 이외의 주요 부스팅 모델들:

**XGBoost (eXtreme Gradient Boosting)**

- XGBoost는 높은 성능과 확장성을 가진 그래디언트 부스팅 라이브러리임. 정규화 기능이 내장되어 있어서 과적합을 잘 방지함.
- 예시: 캐글 대회에서 많이 우승해서 유명해진 알고리즘임. 자동차 엔진 최적화하듯이 성능을 극한까지 끌어올린 거임.

**LightGBM (Light Gradient Boosting Machine)**

- LightGBM은 다른 알고리즘들 중에서 가장 빠른 속도를 보임. 히스토그램 기반 알고리즘을 사용해서 메모리도 적게 쓰고 속도도 빠름.
- 예시: 대용량 데이터에서 빛의 속도처럼 빠르게 학습하는 거임. 나무가 위쪽으로 쭉쭉 자라는 방식(leaf-wise)을 써서 더 효율적임.

**CatBoost (Category Boosting)**

- CatBoost는 범주형 데이터 처리에 특별히 강한 알고리즘임. 범주형 변수를 자동으로 처리해주고 과적합 방지 기능이 뛰어남.
- 예시: 성별, 직업, 지역 같은 범주형 데이터가 많을 때 고양이처럼 민첩하게 처리하는 거임. 기본 설정만으로도 좋은 성능을 냄.

**각 모델의 장단점:**

- 일반적으로 LightGBM과 CatBoost가 XGBoost보다 훨씬 빠르고, 특히 큰 데이터셋에서 그 차이가 더 명확함.
- XGBoost: 안정적이고 검증된 성능, 많은 자료
- LightGBM: 가장 빠른 속도, 대용량 데이터에 적합
- CatBoost: 범주형 데이터 처리 최고, 사용하기 쉬움

## #7. 데이터 분석 심화

**데이터 간의 유사도를 계산할 때, feature의 수가 많다면(예: 100개 이상), 이러한 high-dimensional clustering 문제를 해결하기 위한 방법들을 설명해 주세요.**

- 차원의 저주 문제가 발생함. 100차원 공간에서는 모든 점들이 비슷하게 멀어 보이는 현상이 생김. 넓은 운동장에서 사람들이 다 멀리 있는 것처럼 보이는 거임.
- 해결 방법들: PCA로 차원 축소하기, t-SNE나 UMAP 같은 비선형 차원 축소, 피처 선택으로 중요한 변수만 골라내기, 거리 측정 방법 바꾸기(코사인 유사도 등)

**고유값(eigenvalue)과 고유벡터(eigenvector)에 대해 설명해 주세요.**

- 고유벡터는 행렬을 곱해도 방향이 변하지 않는 특별한 벡터임. 고유값은 그 벡터가 얼마나 늘어나거나 줄어드는지를 나타내는 값임.
- 예시: 고무줄을 늘릴 때 어떤 방향은 2배로 늘어나고(고유값=2) 어떤 방향은 0.5배로 줄어든다면(고유값=0.5), 그 방향들이 고유벡터임.
- 데이터 분석에서는 PCA할 때 주성분을 찾는 데 사용됨. 데이터에서 가장 중요한 방향들을 찾는 거임.

**히스토그램의 주요 단점은 무엇이며, 이를 극복하기 위한 대안적인 시각화 방법을 설명해 주세요.**

- 히스토그램의 단점: 구간(bin) 크기에 따라 모양이 달라짐, 연속성이 없어서 매끄럽지 않음. 라면을 네모 상자에 담으면 원래 모양을 정확히 알 수 없는 것과 같음.
- 대안 방법들: 밀도 곡선(KDE)으로 부드러운 분포 표현, 바이올린 플롯으로 분포 + 박스플롯 결합, 리지 플롯으로 여러 그룹 동시 비교

**장바구니 분석의 활용 사례를 설명해주세요.**

- 마트에서 기저귀와 맥주를 같이 사는 패턴을 발견한 유명한 사례가 있음. 젊은 아빠들이 기저귀 사러 갔다가 맥주도 같이 사는 거였음.
- 비즈니스 인사이트: 기저귀 코너 근처에 맥주를 진열하거나, 기저귀 할인 쿠폰에 맥주 할인도 같이 넣어서 매출 증대 효과를 낼 수 있음.
- 다른 활용: 온라인 쇼핑몰 추천 시스템, 크로스셀링 전략, 진열 위치 최적화

**Support, Confidence, Lift 지표의 정의와 중요성을 설명해 주세요.**

- Support: 전체 거래에서 해당 아이템 조합이 나타나는 비율임. 기저귀+맥주를 사는 사람이 전체의 2%라면 Support = 0.02
- Confidence: A를 산 사람 중에서 B도 같이 산 확률임. 기저귀 산 사람 중 50%가 맥주도 샀다면 Confidence = 0.5
- Lift: 우연보다 얼마나 더 자주 같이 사는지 나타내는 값임. Lift > 1이면 실제 연관성이 있다는 뜻임. 예상보다 2배 더 자주 같이 산다면 Lift = 2

## #8. 협업과 환경관리

**제1종 오류와 제2종 오류에 대해 설명해주세요.**

- 제1종 오류는 실제로는 차이가 없는데 차이가 있다고 잘못 결론내리는 오류임. 화재경보기가 고기 굽는 연기 때문에 울리는 것처럼, 진짜 화재가 아닌데 화재라고 알리는 거임.
- 제2종 오류는 실제로는 차이가 있는데 차이가 없다고 잘못 결론내리는 오류임. 진짜 불이 났는데 화재경보기가 고장나서 안 울리는 거임.

**p값 (p-value)는 무엇인가요?**

- p값은 귀무가설이 참일 때 관찰된 결과가 우연히 나올 확률임. 동전 던지기에서 앞면이 8번 연속 나왔을 때 "이게 정말 우연일까?"하고 의심하는 것과 같음.
- 보통 p < 0.05 (5% 미만)이면 "우연이 아니다"라고 판단함.

## #9. 데이터 엔지니어링

**On-premise, Cloud, Serverless 데이터 웨어하우스의 특징에 대해 각각 설명해주세요.**

- On-premise: 회사 건물 안에 직접 서버를 설치해서 관리하는 방식임. 자기 집에 냉장고 놓고 직접 관리하는 것과 같음. 보안성 높지만 관리 비용 많이 듦.
- Cloud: AWS, GCP 같은 클라우드 업체 서버를 빌려 쓰는 방식임. 냉장고 렌탈하는 것과 같음. 확장성 좋고 초기 비용 적지만 지속 비용 발생.
- Serverless: 서버 관리 없이 필요할 때만 자동으로 작동하는 방식임. 택시 타는 것처럼 쓴 만큼만 비용 내는 거임. 관리 부담 없지만 대용량 처리에는 제한적.

**BigQuery에서 쿼리 성능을 최적화할 수 있는 방법에 대해 설명해주세요.**- BigQuery에서 쿼리 성능 최적화는 입력 데이터 양을 줄이고, 쿼리 계산을 효율적으로 하는 게 핵심임.

**주요 최적화 방법들:**

- 파티션 테이블 사용: 날짜나 정수 범위로 큰 테이블을 나눠서 필요한 부분만 스캔하게 하는 거임. 서랍장에서 원하는 서랍만 열어보는 것과 같음.
- 클러스터링: 특정 컬럼을 기준으로 데이터를 정렬해서 저장하는 거임. 도서관에서 책을 주제별로 정리해 놓은 것처럼 찾기 쉽게 만드는 거임.
- 필요한 컬럼만 선택: SELECT *는 모든 컬럼을 다 읽어야 해서 느림. 필요한 것만 골라서 쓰는 게 좋음.
- JOIN 순서 최적화: 큰 테이블을 왼쪽에, 작은 테이블을 오른쪽에 두면 브로드캐스트 조인으로 빨라짐.
- WHERE 조건 최대한 활용: 데이터를 일찍 필터링해서 처리할 양을 줄이는 거임. 큰 짐에서 필요한 것만 골라서 가는 것과 같음.
- 구체화된 뷰 사용: 자주 쓰는 복잡한 쿼리 결과를 미리 저장해 놓는 거임. 자주 먹는 반찬을 미리 만들어 두는 것과 같음.
- 쿼리 결과 캐싱: 같은 쿼리를 다시 실행하면 이전 결과를 재사용해서 빨라짐.


**데이터 웨어하우스와 데이터 레이크의 차이점은 무엇인가요?**

- 데이터 웨어하우스는 정제되고 구조화된 데이터를 저장하는 창고임. 잘 정리된 도서관처럼 필요한 책을 바로 찾을 수 있음.
- 데이터 레이크는 정제되지 않은 원본 데이터를 그대로 저장하는 호수임. 모든 종류의 물고기가 다 사는 호수처럼 다양한 데이터를 그대로 보관함.

**ETL과 ELT의 차이점은 무엇인가요?**

- ETL은 Extract(추출), Transform(변환), Load(적재) 순서로, 데이터를 가져와서 가공한 후에 웨어하우스에 넣는 방식임. 요리 재료를 사서 → 다듬고 → 냉장고에 넣는 것과 같음.
- ELT는 Extract(추출), Load(적재), Transform(변환) 순서로, 데이터를 먼저 웨어하우스에 넣고 필요할 때 가공하는 방식임. 재료를 사서 → 일단 냉장고에 넣고 → 요리할 때 꺼내서 다듬는 것과 같음.

**데이터 파이프라인을 구축할 때, 데이터 품질을 보장하기 위한 방법들을 설명해 주세요.**

- 데이터 유효성 검사: 데이터가 규칙에 맞는지 확인하는 거임. 전화번호 칸에 숫자만 있는지 확인하는 것과 같음.
- 데이터 프로파일링: 데이터의 통계적 특성을 분석해서 이상한 점을 찾는 거임.
- 데이터 리니지 추적: 데이터가 어디서 와서 어떻게 변했는지 추적하는 거임.
- 모니터링 및 알림: 파이프라인에 문제가 생기면 바로 알림을 받아서 조치하는 거임.

**Airflow에서 DAG란 무엇이며, 주요 구성 요소는 무엇인가요?**

- DAG는 Directed Acyclic Graph의 약자로, 작업들의 실행 순서를 정의한 그래프임. 요리 레시피처럼 어떤 작업을 먼저 하고 다음에 뭘 할지 순서를 정해놓은 거임.
- 주요 구성 요소:
  - DAG 정의: 전체 워크플로우 설정
  - Operator: 실제 작업을 수행하는 단위 (BashOperator, PythonOperator 등)
  - Task: Operator로 생성된 작업 인스턴스
  - Task Dependency: 작업 간의 실행 순서 정의 (task1 >> task2)

**데이터 웨어하우스에서 스타 스키마와 스노우플레이크 스ኪ마의 차이점은 무엇인가요?**

- 스타 스키마는 하나의 사실 테이블과 여러 개의 차원 테이블이 별 모양으로 연결된 구조임. 중앙에 큰 테이블 하나 있고 주변에 작은 테이블들이 붙어있는 모양임.
- 스노우플레이크 스키마는 스타 스키마에서 차원 테이블을 더 정규화해서 눈꽃송이 모양으로 확장한 구조임. 더 복잡하지만 중복이 적음.

## #10. 프로덕트 분석 심화

**사용자 행동 데이터를 기반으로 제품의 특정 기능에 대한 만족도를 측정할 수 있는 지표는 무엇이 있을까요?**

- 기능 채택률: 얼마나 많은 사용자가 그 기능을 처음 사용했는지
- 기능 사용 빈도: 사용자들이 그 기능을 얼마나 자주 사용하는지
- 기능 유지율: 그 기능을 사용한 사용자가 얼마나 오래 남아있는지
- 작업 성공률: 사용자가 그 기능을 사용해서 원하는 작업을 얼마나 성공적으로 마쳤는지
- 이탈률: 그 기능을 사용하는 과정에서 얼마나 많은 사용자가 포기하는지

**제품의 북극성 지표(North Star Metric)를 설정할 때 고려해야 할 점은 무엇인가요?**

- 고객 가치를 반영해야 함: 고객이 제품을 통해 얻는 핵심 가치를 나타내야 함.
- 회사의 비전과 연결되어야 함: 회사의 장기적인 목표와 일치해야 함.
- 측정 가능해야 함: 데이터를 통해 쉽게 측정하고 추적할 수 있어야 함.
- 선행 지표여야 함: 미래의 성공을 예측할 수 있는 지표여야 함.
- 이해하기 쉬워야 함: 모든 팀원이 쉽게 이해하고 기억할 수 있어야 함.

**제품 분석에서 정성적 데이터와 정량적 데이터는 각각 어떤 역할을 하며, 두 데이터를 어떻게 조합하여 활용할 수 있을까요?**

- 정량적 데이터는 "무엇"이 일어났는지 숫자로 보여줌 (예: 이탈률 30%).
- 정성적 데이터는 "왜" 그런 일이 일어났는지 이유를 설명해줌 (예: 사용자 인터뷰를 통해 "버튼이 너무 작아서 누르기 힘들다"는 피드백을 얻음).
- 조합 활용: 정량적 데이터로 문제를 발견하고(이탈률 높음), 정성적 데이터로 원인을 파악해서(버튼이 작음) 해결책을 찾는 방식으로 활용함.

**제품 실험(A/B 테스트)에서 네트워크 효과를 고려해야 하는 경우는 언제이며, 이를 어떻게 해결할 수 있나요?**

- 네트워크 효과는 한 사용자의 경험이 다른 사용자에게 영향을 미치는 경우임. 소셜 미디어, 메시징 앱, 마켓플레이스 같은 제품에서 중요함.
- 예시: A그룹은 새 채팅 기능을 쓰고, B그룹은 못 쓴다면 A그룹 사용자가 B그룹 사용자에게 메시지를 보낼 수 없어서 기능의 진짜 효과를 측정하기 어려움.
- 해결 방안: 사용자 클러스터링(같은 그룹끼리만 상호작용하게 함), 시간 기반 분리(특정 기간 동안 모든 사용자에게 A를 보여주고 다음 기간에 B를 보여줌) 같은 방법을 사용함.

**제품 분석가가 데이터 분석 결과를 효과적으로 전달하기 위해 갖추어야 할 역량은 무엇인가요?**

- 스토리텔링: 데이터를 기반으로 설득력 있는 이야기를 만드는 능력
- 시각화: 복잡한 데이터를 이해하기 쉬운 차트나 그래프로 표현하는 능력
- 비즈니스 이해도: 분석 결과가 비즈니스에 어떤 의미를 갖는지 연결하는 능력
- 커뮤니케이션: 기술적인 내용을 비전문가도 이해할 수 있도록 쉽게 설명하는 능력
- 액션 제안: 분석에서 그치지 않고 다음에 무엇을 해야 할지 구체적인 행동을 제안하는 능력
